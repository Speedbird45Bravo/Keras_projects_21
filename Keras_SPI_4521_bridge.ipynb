{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras_SPI_4521_bridge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYL3BS3aAKYall1CVdf4fL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipsY4ETEii7U"
      },
      "source": [
        "from keras.layers import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# This is a swing at a custom neural network predicting soccer game results based on scores.\n",
        "# I've been in Keras for a few months, but am just starting to understand my way around.\n",
        "df = pd.read_csv(\"https://projects.fivethirtyeight.com/soccer-api/club/spi_matches.csv\").dropna()\n",
        "\n",
        "# We need to calculate one team's aggregate margin in order to determine the result.\n",
        "# We've chosen home for that calculation, but may as well get away as well for good measure.\n",
        "# Then, the absolute margin is the number of goals between the teams.\n",
        "df['h_marg'] = df['score1'] - df['score2']\n",
        "df['a_marg'] = df['score2'] - df['score1']\n",
        "df['margin'] = np.abs(df['score1'] - df['score2'])\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in df['h_marg']:\n",
        "  if i > 0: # If the home team's margin is greater than 0, it's a home win.\n",
        "    results.append(\"HOME WIN\")\n",
        "  elif i < 0: # If the home team's margin is less than 0, it's an away win.\n",
        "    results.append(\"AWAY WIN\")\n",
        "  else: # Otherwise, it's a draw.\n",
        "    results.append(\"DRAW\")\n",
        "\n",
        "df['result'] = results"
      ],
      "execution_count": 670,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1SHdtXTr0Y6"
      },
      "source": [
        "# The model gets a little confused the more numerical rows are fed into it, so we're keeping it simple.\n",
        "X = df[['score1', 'score2', 'margin']].reset_index(drop=True)\n",
        "y = df[['result']].copy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.34)"
      ],
      "execution_count": 671,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDtLz66a8GTP"
      },
      "source": [
        "# Now it's time to make some random test data (separate from the existing test dfs) to use for predictions and accuracy. \n",
        "# First, we need to generate a function to turn the list into a dataframe.\n",
        "\n",
        "def to_df(l1):\n",
        "  df = pd.DataFrame(l1).reset_index(drop=True)\n",
        "  return df\n",
        "\n",
        "def to_cat(cats):\n",
        "  cat = to_categorical(pd.factorize(cats)[0])\n",
        "  return cat\n",
        "\n",
        "# These scores are just # of goals (integers between 0 and 4), so we can use randint for this.\n",
        "t1 = to_df(np.random.randint(0,3,size=60))\n",
        "t2 = to_df(np.random.randint(0,3,size=60))\n",
        "t3 = np.abs(t1) - np.abs(t2)\n",
        "t4 = t2 - t1\n",
        "t5 = t1 - t2\n",
        "\n",
        "t_res = []\n",
        "\n",
        "cols = ['score1', 'score2', 'margin', 'h_margin', 'a_margin']\n",
        "\n",
        "rand_X_test = pd.concat([t1, t2, t3, t4, t5], axis=1)\n",
        "rand_X_test.columns = cols\n",
        "\n",
        "for i in rand_X_test['h_margin']:\n",
        "  if i > 0: # If the home team's margin is greater than 0, it's a home win.\n",
        "    t_res.append(\"HOME WIN\")\n",
        "  elif i < 0: # If the home team's margin is less than 0, it's an away win.\n",
        "    t_res.append(\"AWAY WIN\")\n",
        "  else: # Otherwise, it's a draw.\n",
        "    t_res.append(\"DRAW\")\n",
        "\n",
        "rand_X_test['result'] = t_res\n",
        "rand_y_test = to_cat(rand_X_test['result'])\n",
        "rand_X_test = rand_X_test[['score1', 'score2', 'margin']]\n",
        "rand_reshape = rand_X_test.shape[0] * rand_X_test.shape[1]\n",
        "rand_X_test = np.asarray(rand_X_test)\n",
        "rand_y_test = np.asarray(rand_y_test)"
      ],
      "execution_count": 672,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zf8bCj8SD5R4"
      },
      "source": [
        "# Have to factorize the labels before converting them to categorical (e.g. 1.,0.,0.).\n",
        "y_train = to_cat(y_train['result'])\n",
        "y_test = to_cat(y_test['result'])\n",
        "\n",
        "# The train and test data will be easier to handle in array form.\n",
        "X_train = np.asarray(X_train)\n",
        "X_test = np.asarray(X_test)"
      ],
      "execution_count": 673,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq9DJLDYD90V"
      },
      "source": [
        "# Two layers with a 3 unit output layer given the number of outcomes (HOME WIN, AWAY WIN, DRAW).\n",
        "model = Sequential()\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(20, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 674,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF8WnMkZD-Km",
        "outputId": "098207ae-75f1-4b23-d1fa-17cdc15d6e94"
      },
      "source": [
        "# Definitely excessive on the epochs. ¯\\_(ツ)_/¯\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=128, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 675,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "83/83 [==============================] - 1s 4ms/step - loss: 0.8255 - accuracy: 0.6626 - val_loss: 0.3481 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 1.0000 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.2583e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 2.7189e-04 - accuracy: 1.0000 - val_loss: 2.3362e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 1.4418e-05 - accuracy: 1.0000 - val_loss: 9.1573e-07 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 5.5014e-07 - accuracy: 1.0000 - val_loss: 4.8887e-08 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 3.3765e-08 - accuracy: 1.0000 - val_loss: 7.9141e-09 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 3.5731e-09 - accuracy: 1.0000 - val_loss: 4.5224e-11 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd444552ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 675
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8_qMHJaEHDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12904ec1-e744-41de-9ef1-cbb4326c7244"
      },
      "source": [
        "# Now we will predict results based on the random data we generated.\n",
        "predictions = model.predict(rand_X_test).round(2)\n",
        "predictions = np.asarray(predictions)"
      ],
      "execution_count": 676,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd43b1c7680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbykGDS5EJYG"
      },
      "source": [
        "# Reshaping y_test and predictions to be directly compared 1v1 iteratively.\n",
        "predictions = predictions.reshape(rand_reshape,)\n",
        "predictions = pd.DataFrame(predictions).reset_index(drop=True)\n",
        "rand_y_test = rand_y_test.reshape(rand_reshape,)\n",
        "rand_y_test = pd.DataFrame(rand_y_test).reset_index(drop=True)\n",
        "PvA = pd.concat([rand_y_test, predictions], axis=1)\n",
        "PvA.columns = [\"Predicted\", \"Actual\"]"
      ],
      "execution_count": 677,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_LV-1FeELB2"
      },
      "source": [
        "# If the margin is 0, there is no error. If the margin is 1, there was an error.\n",
        "PvA['Margin'] = np.abs(PvA['Predicted'] - PvA['Actual'])"
      ],
      "execution_count": 678,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPukn4BtEMdW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7521433c-ea18-4d65-899b-f8098472c9e7"
      },
      "source": [
        "# Sum of all of the rows with errors.\n",
        "PvA_err = np.sum(PvA['Margin'])\n",
        "print(PvA_err)"
      ],
      "execution_count": 679,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOmWvh2oEOAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92a7fdc8-1ff1-456c-dea8-08a0561b1011"
      },
      "source": [
        "# Length of the prediction set.\n",
        "PvA_len = len(PvA)\n",
        "print(PvA_len)"
      ],
      "execution_count": 680,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "180\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8ZBN5s5EWP2"
      },
      "source": [
        "# Accuracy metric.\n",
        "PvA_acc = 1-(PvA_err/PvA_len)"
      ],
      "execution_count": 681,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQYkTfgOEa-V",
        "outputId": "e323fdd9-0859-49de-930f-08c608f50815"
      },
      "source": [
        "# AORTD = Accuracy on Random Test Data\n",
        "print(\"AORTD: %.2f\" % (PvA_acc * 100) + \"%\")"
      ],
      "execution_count": 682,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AORTD: 81.11%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9LrfJQ7PbVY",
        "outputId": "22adc07c-3d3e-45c9-dd58-8340ce1adf4e"
      },
      "source": [
        "# I've run a number of models that perform well on either of X & y test comparisons and randomly generated data and labels, but not both.\n",
        "# This one is probably the best balance of performance I've achieved yet.\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test (X & y test) Accuracy: %.2f\" % (accuracy * 100) + \"%\")"
      ],
      "execution_count": 686,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "213/213 [==============================] - 0s 851us/step - loss: 0.0000e+00 - accuracy: 1.0000\n",
            "Test (X & y test) Accuracy: 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}